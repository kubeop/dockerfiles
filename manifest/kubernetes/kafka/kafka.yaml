---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: middleware
  labels:
    app.kubernetes.io/name: kafka
spec:
  clusterIP: None
  ports:
  - name: controller
    port: 9093
  - name: broker
    port: 9092
  selector:
    app.kubernetes.io/name: kafka
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: kafka
  namespace: middleware
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: kafka
  minAvailable: 2
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: middleware
spec:
  replicas: 3
  serviceName: kafka
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app.kubernetes.io/name: kafka
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kafka
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - worker-001
                - worker-002
                - worker-003
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: "app.kubernetes.io/name"
                    operator: In
                    values: 
                    - kafka
              topologyKey: "kubernetes.io/hostname"
      terminationGracePeriodSeconds: 300
      containers:
      - name: kafka
        image: registry.cn-hangzhou.aliyuncs.com/devops-system/kafka:4.0.0
        imagePullPolicy: IfNotPresent
        ports:
        - name: broker
          containerPort: 9092
        - name: controller
          containerPort: 9093
        command:
        - /bin/bash
        - -c
        - |
          # generate config
          configs=(
              process.roles=broker,controller
              
              node.id=${HOSTNAME##*-}
              
              controller.quorum.bootstrap.servers=$(POD_NAME).kafka:9093
              controller.quorum.voters=0@kafka-0.kafka:9093,1@kafka-1.kafka:9093,2@kafka-2.kafka:9093
              
              listeners=PLAINTEXT://:9092,CONTROLLER://:9093
              inter.broker.listener.name=PLAINTEXT
              
              advertised.listeners=PLAINTEXT://$(POD_NAME).kafka:9092,CONTROLLER://$(POD_NAME).kafka:9093
              controller.listener.names=CONTROLLER
              listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
              
              num.network.threads=8
              num.io.threads=16
              socket.send.buffer.bytes=104857600
              socket.receive.buffer.bytes=104857600
              socket.request.max.bytes=104857600
              
              log.dirs=/var/lib/kafka/data
              
              num.partitions=3
              num.replica.fetchers=3
              num.recovery.threads.per.data.dir=1
              
              delete.topic.enable=false
              auto.create.topics.enable=false
              default.replication.factor=3
              leader.replication.throttled.rate=10Gb
              follower.replication.throttled.rate=10Gb
              replica.lag.time.max.ms=30000 
              
              offsets.topic.replication.factor=3
              transaction.state.log.replication.factor=3
              transaction.state.log.min.isr=3
              
              message.max.bytes=10485760
              replica.fetch.max.bytes=10485760
              fetch.message.max.bytes=10485760
              auto.leader.rebalance.enable=true
              controlled.shutdown.enable=true
              
              log.cleaner.enable=true
              log.retention.hours=72
              log.retention.check.interval.ms=300000
              log.segment.bytes=1073741824
              log.flush.interval.messages=10000
              log.flush.interval.ms=5000
              
              group.initial.rebalance.delay.ms=0
          )

          > /opt/kafka/config/server.properties
          for key in "${!configs[@]}"; do
              echo "${configs[$key]}" >> /opt/kafka/config/server.properties
          done
          
          # format cluster id
          /opt/kafka/bin/kafka-storage.sh format \
            -t $CLUSTER_ID \
            -c /opt/kafka/config/server.properties
          
          # start kafka
          /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties \
        env:
        - name: TZ
          value: "Asia/Shanghai"
        - name: KAFKA_HEAP_OPTS
          value : "-Xmx512M -Xms512M"
        - name: KAFKA_JMX_PORT
          value : "9999"
        - name: KAFKA_JMX_HOSTNAME
          value : "$(POD_IP)"
        - name: KAFKA_OPTS
          value: "-Dlogging.level=INFO"
        - name: CLUSTER_ID
          value: "gBcM07cpT1OpA7mpL0tTtA"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        resources:
          requests:
            cpu: 4
            memory: "8Gi"
          limits:
            cpu: 4
            memory: "8Gi"
        livenessProbe:
          exec:
            command:
              - pgrep
              - -f
              - kafka
          initialDelaySeconds: 10
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 3
        readinessProbe:
          tcpSocket:
            port: controller
          initialDelaySeconds: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 6
        volumeMounts:
        - name: data
          mountPath: /var/lib/kafka
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      storageClassName: kafka
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 100Gi
