groups:
- name: etcd
  rules:
  - alert: etcdMembersDown
    expr: |
      max without (endpoint) (
        sum without (instance) (up{job=~".*etcd.*"} == bool 0)
      or
        count without (To) (
          sum without (instance) (rate(etcd_network_peer_sent_failures_total{job=~".*etcd.*"}[120s])) > 0.01
        )
      )
      > 0
    for: 20m
    labels:
      severity: P2
    annotations:
      description: "Etcd集群{{ $labels.job }}的成员{{ $labels.instance }}已不可用超过{{ $value }}分钟"

  - alert: etcdInsufficientMembers
    expr: |
      sum(up{job=~".*etcd.*"} == bool 1) without (instance) < ((count(up{job=~".*etcd.*"}) without (instance) + 1) / 2)
    for: 3m
    labels:
      severity: P1
    annotations:
      description: "Etcd集群{{ $labels.job }}的成员不足{{ $value }}"

  - alert: etcdNoLeader
    expr: |
      etcd_server_has_leader{job=~".*etcd.*"} == 0
    for: 1m
    labels:
      severity: P1
    annotations:
      description: "Etcd集群{{ $labels.job }}的成员{{ $labels.instance }}没有Leader"

  - alert: etcdHighNumberOfLeaderChanges
    expr: |
      increase((max without (instance) (etcd_server_leader_changes_seen_total{job=~".*etcd.*"}) or 0*absent(etcd_server_leader_changes_seen_total{job=~".*etcd.*"}))[15m:1m]) >= 4
    for: 5m
    labels:
      severity: P2
    annotations:
      description: "Etcd集群实例{{ $labels.job }}/{{ $labels.instance }}在最近15分钟{{ $value }}个领导者节点发生变更"

  - alert: etcdHighNumberOfFailedGRPCRequests
    expr: |
      100 * sum(rate(grpc_server_handled_total{job=~".*etcd.*", grpc_code=~"Unknown|FailedPrecondition|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded"}[5m])) without (grpc_type, grpc_code)
        /
      sum(rate(grpc_server_handled_total{job=~".*etcd.*"}[5m])) without (grpc_type, grpc_code)
        > 1
    for: 10m
    labels:
      severity: P2
    annotations:
      description: "Etcd集群实例{{ $labels.job }}/{{ $labels.instance }}的gRPC请求方法{{ $labels.grpc_method }}失败率超过1%，当前失败率{{ $value }}%"

  - alert: etcdHighNumberOfFailedGRPCRequests
    expr: |
      100 * sum(rate(grpc_server_handled_total{job=~".*etcd.*", grpc_code=~"Unknown|FailedPrecondition|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded"}[5m])) without (grpc_type, grpc_code)
        /
      sum(rate(grpc_server_handled_total{job=~".*etcd.*"}[5m])) without (grpc_type, grpc_code)
        > 5
    for: 5m
    labels:
      severity: P1
    annotations:
      description: "Etcd集群实例{{ $labels.job }}/{{ $labels.instance }}的gRPC请求方法{{ $labels.grpc_method }}失败率超过5%，当前失败率{{ $value }}%"

  - alert: etcdGRPCRequestsSlow
    expr: |
      histogram_quantile(0.99, sum(rate(grpc_server_handling_seconds_bucket{job=~".*etcd.*", grpc_method!="Defragment", grpc_type="unary"}[5m])) without(grpc_type))
      > 0.15
    for: 10m
    labels:
      severity: P1
    annotations:
      description: "Etcd集群实例{{ $labels.job }}/{{ $labels.instance }}的gRPC请求方法{{ $labels.grpc_method }}耗时超过{{ $value }}秒"

  - alert: etcdMemberCommunicationSlow
    expr: |
      histogram_quantile(0.99, rate(etcd_network_peer_round_trip_time_seconds_bucket{job=~".*etcd.*"}[5m]))
      > 0.15
    for: 10m
    labels:
      severity: P2
    annotations:
      description: "Etcd集群实例{{ $labels.job }}/{{ $labels.instance }}与{{ $labels.To }}的成员通信耗时超过{{ $value }}秒"

  - alert: etcdHighNumberOfFailedProposals
    expr: |
      rate(etcd_server_proposals_failed_total{job=~".*etcd.*"}[15m]) > 5
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Etcd集群实例{{ $labels.job }}/{{ $labels.instance }}在最近15分钟出现{{ $value }}次提案失败"

  - alert: etcdHighFsyncDurations
    expr: |
      histogram_quantile(0.99, rate(etcd_disk_wal_fsync_duration_seconds_bucket{job=~".*etcd.*"}[5m]))
      > 0.5
    for: 10m
    labels:
      severity: P3
    annotations:
      description: "Etcd集群实例{{ $labels.job }}/{{ $labels.instance }}的同步耗时超过{{ $value }}秒"

  - alert: etcdHighCommitDurations
    expr: |
      histogram_quantile(0.99, rate(etcd_disk_backend_commit_duration_seconds_bucket{job=~".*etcd.*"}[5m]))
      > 0.25
    for: 10m
    labels:
      severity: P3
    annotations:
      description: "Etcd集群实例{{ $labels.job }}/{{ $labels.instance }}的提交耗时超过{{ $value }}秒"

  - alert: etcdDatabaseQuotaLowSpace
    expr: |
      (last_over_time(etcd_mvcc_db_total_size_in_bytes{job=~".*etcd.*"}[5m]) / last_over_time(etcd_server_quota_backend_bytes{job=~".*etcd.*"}[5m]))*100 > 95
    for: 10m
    labels:
      severity: P2
    annotations:
      description: "Etcd集群实例{{ $labels.job }}/{{ $labels.instance }}上的数据库大小超过配额, 请进行碎片整理或增加配额"

  - alert: etcdExcessiveDatabaseGrowth
    expr: |
      predict_linear(etcd_mvcc_db_total_size_in_bytes{job=~".*etcd.*"}[4h], 4*60*60) > etcd_server_quota_backend_bytes{job=~".*etcd.*"}
    for: 10m
    labels:
      severity: P1
    annotations:
      description: "Etcd集群实例{{ $labels.job }}/{{ $labels.instance }}根据最近4小时的写入趋势, 预计在未来4小时内磁盘空间将耗尽"

  - alert: etcdDatabaseHighFragmentationRatio
    expr: |
      (last_over_time(etcd_mvcc_db_total_size_in_use_in_bytes{job=~".*etcd.*"}[5m]) / last_over_time(etcd_mvcc_db_total_size_in_bytes{job=~".*etcd.*"}[5m])) < 0.5 and etcd_mvcc_db_total_size_in_use_in_bytes{job=~".*etcd.*"} > 104857600
    for: 10m
    labels:
      severity: P2
    annotations:
      description: "Etcd集群实例{{ $labels.job }}/{{ $labels.instance }}上的数据大小已达到实际分配磁盘的{{ $value | humanizePercentage }}, 请运行碎片整理程序(例如 etcdctl defrag)以恢复未使用的碎片磁盘空间"

- name: coredns
  rules:
  - alert: CorednsPanicCount
    expr: increase(coredns_panics_total[1m]) > 0
    for: 0m
    labels:
      severity: P2
    annotations:
      description: "Coredns实例{{ $labels.job }}/{{ $labels.instance }}上出现{{ $value }}次Panic"

- name: kube-state-metrics
  rules:
  - alert: KubeStateMetricsListErrors
    expr: |
      (sum(rate(kube_state_metrics_list_total{job="kube-state-metrics",result="error"}[5m])) by (cluster)
        /
      sum(rate(kube_state_metrics_list_total{job="kube-state-metrics"}[5m])) by (cluster))
      > 0.01
    for: 15m
    labels:
      severity: P2
    annotations:
      description: "kube-state-metrics在List操作中出现较多的错误, 可能导致无法暴露kubernetes对象指标"

  - alert: KubeStateMetricsWatchErrors
    expr: |
      (sum(rate(kube_state_metrics_watch_total{job="kube-state-metrics",result="error"}[5m])) by (cluster)
        /
      sum(rate(kube_state_metrics_watch_total{job="kube-state-metrics"}[5m])) by (cluster))
      > 0.01
    for: 15m
    labels:
      severity: P2
    annotations:
      description: "kube-state-metrics在Watch操作中出现较多的错误, 可能导致无法暴露kubernetes对象指标"

  - alert: KubeStateMetricsShardingMismatch
    expr: |
      stdvar (kube_state_metrics_total_shards{job="kube-state-metrics"}) by (cluster) != 0
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "kube-state-metrics的容器组正在使用不同的--total-shards配置, 某些kubernetes对象可能会被暴露多次或者没有暴露"

  - alert: KubeStateMetricsShardsMissing
    expr: |
      2^max(kube_state_metrics_total_shards{job="kube-state-metrics"}) by (cluster) - 1
        -
      sum( 2 ^ max by (cluster, shard_ordinal) (kube_state_metrics_shard_ordinal{job="kube-state-metrics"}) ) by (cluster)
      != 0
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "kube-state-metrics分片丢失, 一些kubernetes对象没有暴露"

- name: kubernetes
  rules:
  - alert: KubeDiskPressure
    expr: |-
      kube_node_status_condition{condition="DiskPressure",status="true"} == 1
    for: 2m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}出现磁盘压力, 请检查节点磁盘"

  - alert: KubeMemoryPressure
    expr: |-
      kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
    for: 2m
    labels:
      severity: P2
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}出现内存压力, 请检查节点内存"

  - alert: KubeNodeNetworkUnavailable
    expr: |-
      kube_node_status_condition{condition="NetworkUnavailable",status="true"} == 1
    for: 2m
    labels:
      severity: P1
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}网络不可用, 请检查节点网络"

  - alert: KubePersistentvolumeclaimPending
    expr: |-
      kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
    for: 2m
    labels:
      severity: P4
    annotations:
      description: "Kubernetes存储声明实例{{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }}处于Pending状态"

- name: kubernetes-apps
  rules:
  - alert: KubePodOomKiller
    expr: |-
      (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
    for: 0m
    labels:
      severity: P1
    annotations:
      description: "Kubernetes容器实例{{ $labels.namespace }}/{{ $labels.pod }}/{{ $labels.container }}在最近10分钟被OOMKilled了{{ $value }}次"

  - alert: KubePodMemory
    expr: |-
      sum(container_memory_working_set_bytes{job="kubelet", metrics_path="/metrics/cadvisor", container!="", image!=""}) by (container,pod,namespace,cluster) / sum(cluster:namespace:pod_memory:active:kube_pod_container_resource_limits) by (container ,pod,namespace,cluster) * 100 > 90
    for: 5m
    labels:
      severity: P2
    annotations:
      description: "Kubernetes容器实例{{ $labels.namespace }}/{{ $labels.pod }}/{{ $labels.container }}内存使用率超过了90%, 触发时值为: {{ $value | humanize }}%"

  - alert: KubePodCrashLooping
    expr: |
      max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics"}[5m]) >= 1
    for: 15m
    labels:
      severity: P1
    annotations:
      description: "Kubernetes容器实例{{ $labels.namespace }}/{{ $labels.pod }}/{{ $labels.container }}处于CrashLoopBackOff状态, 请尽快检查容器以避免影响业务"

  - alert: KubePodNotReady
    expr: |
      sum by (namespace, pod, cluster) (
        max by(namespace, pod, cluster) (
          kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown|Failed"}
        ) * on(namespace, pod, cluster) group_left(owner_kind) topk by(namespace, pod, cluster) (
          1, max by(namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"})
        )
      ) > 0
    for: 15m
    labels:
      severity: P1
    annotations:
      description: "Kubernetes容器组实例{{ $labels.namespace }}/{{ $labels.pod }}处于未就绪状态超过15分钟"

  - alert: KubeDeploymentGenerationMismatch
    expr: |
      kube_deployment_status_observed_generation{job="kube-state-metrics"}
        !=
      kube_deployment_metadata_generation{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: P2
    annotations:
      description: "Kubernetes无状态实例{{ $labels.namespace }}/{{ $labels.deployment }}部署配置不一致, 可能部署失败, 请尽快处理以避免影响业务"

  - alert: KubeDeploymentReplicasMismatch
    expr: |
      (
        kube_deployment_spec_replicas{job="kube-state-metrics"}
          >
        kube_deployment_status_replicas_available{job="kube-state-metrics"}
      ) and (
        changes(kube_deployment_status_replicas_updated{job="kube-state-metrics"}[10m])
          ==
        0
      )
    for: 15m
    labels:
      severity: P2
    annotations:
      description: "Kubernetes无状态实例{{ $labels.namespace }}/{{ $labels.deployment }}持续超过15分钟跟预期的副本数量不一致"

  - alert: KubeDeploymentRolloutStuck
    expr: |
      kube_deployment_status_condition{condition="Progressing", status="false",job="kube-state-metrics"}
      != 0
    for: 15m
    labels:
      severity: P2
    annotations:
      description: "Kubernetes无状态实例{{ $labels.namespace }}/{{ $labels.deployment }}持续超过15分钟未完成滚动更新"

  - alert: KubeStatefulSetReplicasMismatch
    expr: |
      (
        kube_statefulset_status_replicas_ready{job="kube-state-metrics"}
          !=
        kube_statefulset_replicas{job="kube-state-metrics"}
      ) and (
        changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[10m])
          ==
        0
      )
    for: 15m
    labels:
      severity: P2
    annotations:
      description: "Kubernetes有状态实例{{ $labels.namespace }}/{{ $labels.statefulset }}持续超过15分钟跟预期的副本数量不一致"

  - alert: KubeStatefulSetGenerationMismatch
    expr: |
      kube_statefulset_status_observed_generation{job="kube-state-metrics"}
        !=
      kube_statefulset_metadata_generation{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes有状态实例{{ $labels.namespace }}/{{ $labels.statefulset }} 部署配置不匹配，可能部署失败, 请尽快处理以避免影响业务"

  - alert: KubeStatefulSetUpdateNotRolledOut
    expr: |
      (
        max by(namespace, statefulset, job, cluster) (
          kube_statefulset_status_current_revision{job="kube-state-metrics"}
            unless
          kube_statefulset_status_update_revision{job="kube-state-metrics"}
        )
          * on(namespace, statefulset, job, cluster)
        (
          kube_statefulset_replicas{job="kube-state-metrics"}
            !=
          kube_statefulset_status_replicas_updated{job="kube-state-metrics"}
        )
      )  and on(namespace, statefulset, job, cluster) (
        changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[5m])
          ==
        0
      )
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes有状态实例{{ $labels.namespace }}/{{ $labels.statefulset }}的更新尚未执行"

  - alert: KubeDaemonSetRolloutStuck
    expr: |
      (
        (
          kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"}
            !=
          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
        ) or (
          kube_daemonset_status_number_misscheduled{job="kube-state-metrics"}
            !=
          0
        ) or (
          kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"}
            !=
          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
        ) or (
          kube_daemonset_status_number_available{job="kube-state-metrics"}
            !=
          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
        )
      ) and (
        changes(kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"}[5m])
          ==
        0
      )
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes守护进程集实例{{ $labels.namespace }}/{{ $labels.daemonset }}超过15分钟没有完成或进展"

  - alert: KubeContainerWaiting
    expr: |
      kube_pod_container_status_waiting_reason{reason!="CrashLoopBackOff", job="kube-state-metrics"} > 0
    for: 1h
    labels:
      severity: P3
    annotations:
      description: "Kubernetes容器实例{{ $labels.namespace }}/{{ $labels.pod }}/{{ $labels.container }}处于等待状态超过1小时, 原因是: {{ $labels.reason }}"

  - alert: KubeDaemonSetNotScheduled
    expr: |
      kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
        -
      kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} > 0
    for: 10m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes守护进程集实例{{ $labels.namespace }}/{{ $labels.daemonset }}有{{ $value }}容器组未进行调度"

  - alert: KubeDaemonSetMisScheduled
    expr: |
      kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} > 0
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes守护进程集实例{{ $labels.namespace }}/{{ $labels.daemonset }}有{{ $value }}容器组在不应该运行的节点运行"

  - alert: KubeJobNotCompleted
    expr: |
      time() - max by(namespace, job_name, cluster) (kube_job_status_start_time{job="kube-state-metrics"}
        and
      kube_job_status_active{job="kube-state-metrics"} > 0) > 43200
    labels:
      severity: P3
    annotations:
      description: "Kubernetes任务实例{{ $labels.namespace }}/{{ $labels.job_name }}超过12小时没有执行完成"

  - alert: KubeJobFailed
    expr: |
      kube_job_failed{job="kube-state-metrics"}  > 0
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes任务实例{{ $labels.namespace }}/{{ $labels.job_name }}未能正确执行完成"

  - alert: KubeCronjobSuspended
    expr: kube_cronjob_spec_suspend != 0
    for: 1m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes定时任务实例{{ $labels.namespace }}/{{ $labels.cronjob }}执行失败"

  - alert: KubeHpaReplicasMismatch
    expr: |
      (kube_horizontalpodautoscaler_status_desired_replicas{job="kube-state-metrics"}
        !=
      kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"})
        and
      (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
        >
      kube_horizontalpodautoscaler_spec_min_replicas{job="kube-state-metrics"})
        and
      (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
        <
      kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"})
        and
      changes(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}[15m]) == 0
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes弹性扩缩容实例{{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }}与所需副本数量不匹配的时间超过15分钟"

  - alert: KubeHpaMaxedOut
    expr: |
      kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
        ==
      kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes弹性扩缩容实例{{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }}已以最大副本数运行超过15分钟"

  - alert: KubePdbNotEnoughHealthyPods
    expr: |
      (
        kube_poddisruptionbudget_status_desired_healthy{job="kube-state-metrics"}
        -
        kube_poddisruptionbudget_status_current_healthy{job="kube-state-metrics"}
      )
      > 0
    for: 15m
    labels:
      severity: P2
    annotations:
      description: "Kubernetes PDB实例{{ $labels.namespace }}/{{ $labels.poddisruptionbudget }}期望有{{ $value }}个健康的Pod, 但当前只有{{ $labels.current_healthy }}个健康的Pod"

- name: kubernetes-resources
  rules:
  - alert: KubeCPUOvercommit
    expr: |
      # Non-HA clusters.
      (
        (
          sum by(cluster) (namespace_cpu:kube_pod_container_resource_requests:sum{})
          -
          sum by(cluster) (kube_node_status_allocatable{job="kube-state-metrics",resource="cpu"}) > 0
        )
        and
        count by (cluster) (max by (cluster, node) (kube_node_role{job="kube-state-metrics", role="control-plane"})) < 3
      )
      or
      # HA clusters.
      (
        sum by(cluster) (namespace_cpu:kube_pod_container_resource_requests:sum{})
        -
        (
          # Skip clusters with only one allocatable node.
          (
            sum by (cluster) (kube_node_status_allocatable{job="kube-state-metrics",resource="cpu"})
            -
            max by (cluster) (kube_node_status_allocatable{job="kube-state-metrics",resource="cpu"})
          ) > 0
        ) > 0
      )
    for: 10m
    labels:
      severity: P2
    annotations:
      description: "Kubernetes集群{{ $labels.cluster }}已超量使用CPU资源请求, 可能会影响服务运行"

  - alert: KubeMemoryOvercommit
    expr: |
      # Non-HA clusters.
      (
        (
          sum by(cluster) (namespace_memory:kube_pod_container_resource_requests:sum{})
          -
          sum by(cluster) (kube_node_status_allocatable{job="kube-state-metrics",resource="memory"}) > 0
        )
        and
        count by (cluster) (max by (cluster, node) (kube_node_role{job="kube-state-metrics", role="control-plane"})) < 3
      )
      or
      # HA clusters.
      (
        sum by(cluster) (namespace_memory:kube_pod_container_resource_requests:sum{})
        -
        (
          # Skip clusters with only one allocatable node.
          (
            sum by (cluster) (kube_node_status_allocatable{job="kube-state-metrics",resource="memory"})
            -
            max by (cluster) (kube_node_status_allocatable{job="kube-state-metrics",resource="memory"})
          ) > 0
        ) > 0
      )
    for: 10m
    labels:
      severity: P2
    annotations:
      description: "Kubernetes集群{{ $labels.cluster }}已超量使用内存资源请求, 可能会影响服务运行"

  - alert: KubeCPUQuotaOvercommit
    expr: |
      sum by(cluster) (
        min without(resource) (kube_resourcequota{job="kube-state-metrics", type="hard", resource=~"(cpu|requests.cpu)"})
      )
      /
      sum by(cluster) (
        kube_node_status_allocatable{resource="cpu", job="kube-state-metrics"}
      ) > 1.5
    for: 5m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes集群{{ $labels.cluster }}已超量使用命名空间的CPU资源请求, 可能会影响服务运行"

  - alert: KubeMemoryQuotaOvercommit
    expr: |
      sum by(cluster) (
        min without(resource) (kube_resourcequota{job="kube-state-metrics", type="hard", resource=~"(memory|requests.memory)"})
      )
      /
      sum by(cluster) (
        kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}
      ) > 1.5
    for: 5m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes集群{{ $labels.cluster }}已超量使用命名空间的内存资源请求, 可能会影响服务运行"

  - alert: KubeQuotaAlmostFull
    expr: |
      kube_resourcequota{job="kube-state-metrics", type="used"}
        / ignoring(instance, job, type)
      (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)
        > 0.9 < 1
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes集群的命名空间{{ $labels.namespace }}的{{ $labels.resource }}配额已使用{{ $value | humanizePercentage }}, 命名空间配额即将用满"

  - alert: KubeQuotaFullyUsed
    expr: |
      kube_resourcequota{job="kube-state-metrics", type="used"}
        / ignoring(instance, job, type)
      (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)
        == 1
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes集群的命名空间{{ $labels.namespace }}的{{ $labels.resource }}配额已使用{{ $value | humanizePercentage }}, 命名空间配额已完全使用"

  - alert: KubeQuotaExceeded
    expr: |
      kube_resourcequota{job="kube-state-metrics", type="used"}
        / ignoring(instance, job, type)
      (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)
        > 1
    for: 15m
    labels:
      severity: P2
    annotations:
      description: "Kubernetes集群的命名空间{{ $labels.namespace }}的{{ $labels.resource }}配额已使用{{ $value | humanizePercentage }}, 命名空间配额已超出限制"

  - alert: CPUThrottlingHigh
    expr: |
      sum(increase(container_cpu_cfs_throttled_periods_total{container!="", job="kubelet", metrics_path="/metrics/cadvisor", }[5m])) without (id, metrics_path, name, image, endpoint, job, node)
        / on (cluster, namespace, pod, container, instance) group_left
      sum(increase(container_cpu_cfs_periods_total{job="kubelet", metrics_path="/metrics/cadvisor", }[5m])) without (id, metrics_path, name, image, endpoint, job, node)
        > ( 25 / 100 )
    for: 15m
   labels:
     severity: P4
   annotations:
     description: "Kubernetes集群{{ $labels.namespace }}/{{ $labels.pod }} /{{ $labels.container }}容器受到{{ $value | humanizePercentage }}的CPU限流"

- name: kubernetes-storage
  rules:
  - alert: KubePersistentVolumeFillingUp
    expr: |
      (
        kubelet_volume_stats_available_bytes{job="kubelet", metrics_path="/metrics"}
          /
        kubelet_volume_stats_capacity_bytes{job="kubelet", metrics_path="/metrics"}
      ) < 0.03
      and
      kubelet_volume_stats_used_bytes{job="kubelet", metrics_path="/metrics"} > 0
      unless on(cluster, namespace, persistentvolumeclaim)
      kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
      unless on(cluster, namespace, persistentvolumeclaim)
      kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
    for: 1m
    labels:
      severity: P1
    annotations:
      description: "Kubernetes集群的持久卷声明{{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }}仅剩余{{ $value | humanizePercentage }}的空间"

  - alert: KubePersistentVolumeFillingUp
    expr: |
      (
        kubelet_volume_stats_available_bytes{job="kubelet", metrics_path="/metrics"}
          /
        kubelet_volume_stats_capacity_bytes{job="kubelet", metrics_path="/metrics"}
      ) < 0.15
      and
      kubelet_volume_stats_used_bytes{job="kubelet", metrics_path="/metrics"} > 0
      and
      predict_linear(kubelet_volume_stats_available_bytes{job="kubelet", metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
      unless on(cluster, namespace, persistentvolumeclaim)
      kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
      unless on(cluster, namespace, persistentvolumeclaim)
      kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
    for: 1h
    labels:
      severity: P3
    annotations:
      description: "Kubernetes集群的持久卷声明{{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }}根据最近采集的情况, 预计将在4天内用尽, 当前剩余: {{ $value | humanizePercentage }}"

  - alert: KubePersistentVolumeInodesFillingUp
    expr: |
      (
        kubelet_volume_stats_inodes_free{job="kubelet", metrics_path="/metrics"}
          /
        kubelet_volume_stats_inodes{job="kubelet", metrics_path="/metrics"}
      ) < 0.03
      and
      kubelet_volume_stats_inodes_used{job="kubelet", metrics_path="/metrics"} > 0
      unless on(cluster, namespace, persistentvolumeclaim)
      kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
      unless on(cluster, namespace, persistentvolumeclaim)
      kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
    for: 1m
    labels:
      severity: P1
    annotations:
      description: "Kubernetes集群的持久卷声明{{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }}仅剩余{{ $value | humanizePercentage }}的inode"

  - alert: KubePersistentVolumeInodesFillingUp
    expr: |
      (
        kubelet_volume_stats_inodes_free{job="kubelet", metrics_path="/metrics"}
          /
        kubelet_volume_stats_inodes{job="kubelet", metrics_path="/metrics"}
      ) < 0.15
      and
      kubelet_volume_stats_inodes_used{job="kubelet", metrics_path="/metrics"} > 0
      and
      predict_linear(kubelet_volume_stats_inodes_free{job="kubelet", metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
      unless on(cluster, namespace, persistentvolumeclaim)
      kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
      unless on(cluster, namespace, persistentvolumeclaim)
      kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
    for: 1h
    labels:
      severity: P3
    annotations:
      description: "Kubernetes集群的持久卷声明{{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }}根据最近采集的情况, 预计将在4天内用尽, 当前剩余: {{ $value | humanizePercentage }}"

  - alert: KubePersistentVolumeErrors
    expr: |
      kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"} > 0
    for: 5m
    labels:
      severity: P1
    annotations:
      description: "Kubernetes集群的持久卷{{ $labels.persistentvolume }}状态为{{ $labels.phase }}, 持久卷存在问题"

- name: kubernetes-system
  rules:
  - alert: KubeVersionMismatch
    expr: |
      count by (cluster) (count by (git_version, cluster) (label_replace(kubernetes_build_info{job!~"kube-dns|coredns"},"git_version","$1","git_version","(v[0-9]*.[0-9]*).*"))) > 1
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes集群存在{{ $value }}个不同的语义版本的Kubernetes组件在运行"

  - alert: KubeClientErrors
    expr: |
      (sum(rate(rest_client_requests_total{job="apiserver",code=~"5.."}[5m])) by (cluster, instance, job, namespace)
        /
      sum(rate(rest_client_requests_total{job="apiserver"}[5m])) by (cluster, instance, job, namespace))
      > 0.01
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes集群的ApiServer客户端{{ $labels.job }}/{{ $labels.instance }}出现了{{ $value | humanizePercentage }}的错误"

- name: kube-apiserver-slos
  rules:
  - alert: KubeAPIErrorBudgetBurn
    expr: |
      sum by(cluster) (apiserver_request:burnrate1h) > (14.40 * 0.01000)
      and on(cluster)
      sum by(cluster) (apiserver_request:burnrate5m) > (14.40 * 0.01000)
    for: 2m
    labels:
      long: 1h
      severity: P1
      short: 5m
    annotations:
      description: "Kubernetes集群的ApiServer消耗了过多的错误预算"

  - alert: KubeAPIErrorBudgetBurn
    expr: |
      sum by(cluster) (apiserver_request:burnrate6h) > (6.00 * 0.01000)
      and on(cluster)
      sum by(cluster) (apiserver_request:burnrate30m) > (6.00 * 0.01000)
    for: 15m
    labels:
      long: 6h
      severity: P2
      short: 30m
    annotations:
      description: "Kubernetes集群的ApiServer消耗了过多的错误预算"

  - alert: KubeAPIErrorBudgetBurn
    expr: |
      sum by(cluster) (apiserver_request:burnrate1d) > (3.00 * 0.01000)
      and on(cluster)
      sum by(cluster) (apiserver_request:burnrate2h) > (3.00 * 0.01000)
    for: 1h
    labels:
      long: 1d
      severity: P1
      short: 2h
    annotations:
      description: "Kubernetes集群的ApiServer消耗了过多的错误预算"

  - alert: KubeAPIErrorBudgetBurn
    expr: |
      sum by(cluster) (apiserver_request:burnrate3d) > (1.00 * 0.01000)
      and on(cluster)
      sum by(cluster) (apiserver_request:burnrate6h) > (1.00 * 0.01000)
    for: 3h
    labels:
      long: 3d
      severity: P2
      short: 6h
    annotations:
      description: "Kubernetes集群的ApiServer消耗了过多的错误预算"

- name: kubernetes-system-apiserver
  rules:
  - alert: KubeClientCertificateExpiration
    expr: |
      histogram_quantile(0.01, sum without (namespace, service, endpoint) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 604800
      and
      on(job, cluster, instance) apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0
    for: 5m
    labels:
      severity: P1
    annotations:
      description: "kubernetes集群与apiserver进行身份验证的客户端证书将在7天内过期, 剩余天数: {{$value | humanizeDuration}}"

  - alert: KubeClientCertificateExpiration
    expr: |
      histogram_quantile(0.01, sum without (namespace, service, endpoint) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 86400
      and
      on(job, cluster, instance) apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0
    for: 5m
    labels:
      severity: P2
    annotations:
      description: "kubernetes集群与apiserver进行身份验证的客户端证书将在24小时内过期, 剩余天数: {{$value | humanizeDuration}}"

  - alert: KubeAggregatedAPIErrors
    expr: |
      sum by(cluster, instance, name, reason)(increase(aggregator_unavailable_apiservice_total{job="apiserver"}[1m])) > 0
    for: 10m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes 聚合API{{ $labels.namespace }}/{{ $labels.name }}在最近10分钟出现了{{ $labels.reason }}错误"

  - alert: KubeAggregatedAPIDown
    expr: |
      (1 - max by(name, namespace, cluster)(avg_over_time(aggregator_unavailable_apiservice{job="apiserver"}[10m]))) * 100 < 85
    for: 5m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes 聚合API {{ $labels.namespace }}/{{ $labels.name }}在最近10分钟仅有{{ $value | humanize }}%可用"

  - alert: KubeAPIDown
    expr: |
      absent(up{job="apiserver"} == 1)
    for: 15m
    labels:
      severity: P1
    annotations:
      description: "Kubernetes集群的ApiServer实例{{ $labels.job }}/{{ $labels.instance }}从监控目标中消失"

  - alert: KubeAPITerminatedRequests
    expr: |
      sum by(cluster) (rate(apiserver_request_terminations_total{job="apiserver"}[10m])) / ( sum by(cluster) (rate(apiserver_request_total{job="apiserver"}[10m])) + sum by(cluster) (rate(apiserver_request_terminations_total{job="apiserver"}[10m])) ) > 0.20
    for: 5m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes集群的ApiServer已终止了{{ $value | humanizePercentage }}的请求"

- name: kubernetes-system-kubelet
  rules:
  - alert: KubeNodeNotReady
    expr: |
      kube_node_status_condition{job="kube-state-metrics",condition="Ready",status="true"} == 0
      and on (cluster, node)
      kube_node_spec_unschedulable{job="kube-state-metrics"} == 0
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}已超过15分钟未就绪"

  - alert: KubeNodePressure
    expr: |
      kube_node_status_condition{job="kube-state-metrics",condition=~"(MemoryPressure|DiskPressure|PIDPressure)",status="true"} == 1
      and on (cluster, node)
      kube_node_spec_unschedulable{job="kube-state-metrics"} == 0
    for: 10m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}已超过10分钟处于压力状态"

  - alert: KubeNodeUnreachable
    expr: |
      (kube_node_spec_taint{job="kube-state-metrics",key="node.kubernetes.io/unreachable",effect="NoSchedule"} unless ignoring(key,value) kube_node_spec_taint{job="kube-state-metrics",key=~"ToBeDeletedByClusterAutoscaler|cloud.google.com/impending-node-termination|aws-node-termination-handler/spot-itn"}) == 1
    for: 15m
    labels:
      severity: P1
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}无法访问，某些工作负载可能无法访问或重新调度"

  - alert: KubeletTooManyPods
    expr: |
      (
        max by (cluster, instance) (
          kubelet_running_pods{job="kubelet", metrics_path="/metrics"} > 1
        )
        * on (cluster, instance) group_left(node)
        max by (cluster, instance, node) (
          kubelet_node_name{job="kubelet", metrics_path="/metrics"}
        )
      )
      / on (cluster, node) group_left()
      max by (cluster, node) (
        kube_node_status_capacity{job="kube-state-metrics", resource="pods"} != 1
      ) > 0.95
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}的kubelet运行的容器组数量已经超过总数的{{ $value | humanizePercentage }}"

  - alert: KubeNodeReadinessFlapping
    expr: |
      sum(changes(kube_node_status_condition{job="kube-state-metrics",status="true",condition="Ready"}[15m])) by (cluster, node) > 2
      and on (cluster, node)
      kube_node_spec_unschedulable{job="kube-state-metrics"} == 0
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}的就绪状态在最近15分钟已更改{{ $value }}次"

  - alert: KubeNodeEviction
    expr: |
      sum(rate(kubelet_evictions{job="kubelet", metrics_path="/metrics"}[15m])) by(cluster, eviction_signal, instance)
      * on (cluster, instance) group_left(node)
      max by (cluster, instance, node) (
        kubelet_node_name{job="kubelet", metrics_path="/metrics"}
      )
      > 0
    for: 0s
    labels:
      severity: P3
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}由于{{ $labels.eviction_signal }}正在驱逐Pod, 通常是由于Pod超出内存/临时存储限制所致"

  - alert: KubeletPlegDurationHigh
    expr: |
      node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile{quantile="0.99"} >= 10
    for: 5m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}上kubelet容器组的生命周期生成器耗时超过{{ $value }}s"

  - alert: KubeletPodStartUpLatencyHigh
    expr: |
      histogram_quantile(0.99,
        sum by (cluster, instance, le) (
          topk by (cluster, instance, le, operation_type) (1,
            rate(kubelet_pod_worker_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])
          )
        )
      )
      * on(cluster, instance) group_left(node)
      topk by (cluster, instance, node) (1,
        kubelet_node_name{job="kubelet", metrics_path="/metrics"}
      )
      > 60
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}上的kubelet启动容器组的耗时超过了{{ $value }}s"

  - alert: KubeletClientCertificateExpiration
    expr: |
      kubelet_certificate_manager_client_ttl_seconds < 604800
    labels:
      severity: P2
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}上的kubelet客户端证书将在{{ $value | humanizeDuration }}后过期"

  - alert: KubeletClientCertificateExpiration
    expr: |
      kubelet_certificate_manager_client_ttl_seconds < 86400
    labels:
      severity: P1
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}上的kubelet客户端证书将在{{ $value | humanizeDuration }}后过期"

  - alert: KubeletServerCertificateExpiration
    expr: |
      kubelet_certificate_manager_server_ttl_seconds < 604800
    labels:
      severity: P2
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}上的kubelet服务端证书将在{{ $value | humanizeDuration }}后过期"

  - alert: KubeletServerCertificateExpiration
    expr: |
      kubelet_certificate_manager_server_ttl_seconds < 86400
    labels:
      severity: P1
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}上的kubelet服务端证书将在{{ $value | humanizeDuration }}后过期"

  - alert: KubeletClientCertificateRenewalErrors
    expr: |
      increase(kubelet_certificate_manager_client_expiration_renew_errors[5m]) > 0
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}上kubelet客户端证书在最近5分钟有{{ $value | humanize }}条错误, 导致证书更新失败"

  - alert: KubeletServerCertificateRenewalErrors
    expr: |
      increase(kubelet_server_expiration_renew_errors[5m]) > 0
    for: 15m
    labels:
      severity: P3
    annotations:
      description: "Kubernetes节点实例{{ $labels.node }}上kubelet服务端证书在最近5分钟有{{ $value | humanize }}条错误, 导致证书更新失败"

  - alert: KubeletDown
    expr: |
      absent(up{job="kubelet", metrics_path="/metrics"} == 1)
    for: 15m
    labels:
      severity: P1
    annotations:
      description: "Kubernetes节点实例{{ $labels.instance }}上的kubelet组件已从监控目标中消失"

- name: kubernetes-system-scheduler
  rules:
  - alert: KubeSchedulerDown
    expr: |
      absent(up{job="kube-scheduler"} == 1)
    for: 15m
    labels:
      severity: P1
    annotations:
      description: "Kubernetes节点实例{{ $labels.instance }}上的kube-scheduler组件已从监控目标中消失"

- name: kubernetes-system-controller-manager
  rules:
  - alert: KubeControllerManagerDown
    expr: |
      absent(up{job="kube-controller-manager"} == 1)
    for: 15m
    labels:
      severity: P1
    annotations:
      description: "Kubernetes节点实例{{ $labels.instance }}上的kube-controller-manager组件已从监控目标中消失"
